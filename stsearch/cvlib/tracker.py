import collections
import functools
import time
import typing

import cv2
import numpy as np

from rekall.bounds import Bounds3D
from rekall.predicates import _height, _iou, _width

from stsearch import Graph, Interval, Op
from stsearch.cvlib.detection import DEFAULT_DETECTION_KEY
from stsearch.op import Flatten, Map
from stsearch.parallel import ParallelMap
from stsearch.third_party.sorttrack.sort import Sort as SORTTrack
from stsearch.videolib import AbstractVideoDecoder, VideoFrameInterval


def _cv2_track_from_box(decoder, window, step, trajectory_key) -> typing.Callable[[Interval,], Interval]:

    def new_fn(i1: Interval) -> Interval:
        tracker = cv2.TrackerCSRT_create() # best accuracy but slow
        # tracker = cv2.TrackerKCF_create()
        ret_bounds = i1.bounds
        ret_payload = {trajectory_key: [VideoFrameInterval(i1.bounds, root_decoder=decoder), ]}

        # buffer all frames in window at once
        start_fid = min(i1['t1'], decoder.frame_count - 1)  # inclusive
        end_fid = min(i1['t1'] + window, decoder.frame_count)  # exclusive
        frames_to_track = decoder.get_frame_interval(start_fid, end_fid, step)

        # init tracker. For tracking, we must get whole frames
        H, W = frames_to_track[0].shape[:2]
        # tracking box in cv2 is the form (x, y, w, h)
        init_box = np.array([i1['x1']*W, i1['y1']*H, _width(i1)*W, _height(i1)*H]).astype(np.int32)
        tracker.init(frames_to_track[0], tuple(init_box))

        # iterate remaining frames and update tracker, get tracked result
        for ts, next_frame in zip(range(start_fid+step, end_fid, step), frames_to_track[1:]):
            (success, next_box) = tracker.update(next_frame)

            if success:
                x, y, w, h = next_box # pixel coord
                x1, y1, x2, y2 = x, y, x+w, y+h
                x1, y1, x2, y2 = x1/W, y1/H, x2/W, y2/H # relative coord
                next_bounds = Bounds3D(ts, ts, x1, x2, y1, y2)
                ret_bounds = ret_bounds.span(next_bounds)
                ret_payload[trajectory_key].append(
                    VideoFrameInterval(next_bounds, root_decoder=decoder)
                )
            else:
                break
        
        return Interval(ret_bounds, ret_payload)

    return new_fn

class TrackFromBox(Graph):

    def __init__(self, decoder, window, step=1, trajectory_key='trajectory', name=None, parallel_workers=1):
        super().__init__()
        assert isinstance(decoder, AbstractVideoDecoder)
        self.decoder = decoder
        self.window = window
        self.step = step
        self.trajectory_key = trajectory_key
        self.name = name
        self.parallel_workers = parallel_workers

    def call(self, instream):
        if self.parallel_workers == 1:
            return Map(
                map_fn=_cv2_track_from_box(self.decoder, self.window, self.step, self.trajectory_key),
                name=f"{self.__class__.__name__}:{self.name}"
            )(instream)
        else:
            return ParallelMap(
                map_fn=_cv2_track_from_box(self.decoder, self.window, self.step, self.trajectory_key),
                name=f"{self.__class__.__name__}:{self.name}",
                max_workers=self.parallel_workers
            )(instream)


def get_boxes_from_detection(
    classes: typing.Collection[str] , 
    min_score, 
    detection_key=DEFAULT_DETECTION_KEY) -> typing.Callable[[Interval], np.ndarray]:
    """Returns an n_object x 5 array of [x_min, y_min, x_max, y_max, score].
    This format is used by multi-object trackers.
    Assume input is generated by stsearch.cvlib.detection.Detection.

    Args:
        classes ([type]): [description]
        min_score ([type]): [description]
    """

    def new_fn(intrvl: Interval) -> np.ndarray:
        ret = []
        detections = intrvl.payload[detection_key]
        for box, score, class_name in zip(detections['detection_boxes'], detections['detection_scores'], detections['detection_names']):
            if score < min_score:
                break
            if class_name in classes:
                # create new patch
                top, left, bottom, right = box  # TF return between 0~1
                ret.append([left, top, right, bottom, score])

        ret = np.array(ret, dtype=np.float) if ret else np.empty((0,5))
        return ret

    return new_fn


class SORTTrackByDetection(Op):

    # Hopefully relative coords work as well

    def __init__(
        self, 
        get_boxes_fn: typing.Callable[[Interval], np.ndarray], 
        window: int,
        trajectory_key:str = 'trajectory',
        name = None,
        max_age=1, min_hits=3, iou_threshold=0.3):

        super().__init__(name)

        assert callable(get_boxes_fn)
        self.get_boxes_fn = get_boxes_fn
        self.window = window
        self.trajectory_key = trajectory_key
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold 

        self.trackings = collections.defaultdict(list) # id -> list of boxes [t1, x1, y1, x2, y2]
        self.result_buffer = [] # Intervals with trajectory
        self.cur_t1 = float('-inf')  # t1 of the starting point of the current tracking
        self.tracker = None
        self.done = False

    def call(self, instream):
        self.instream = instream

    def execute(self):
        
        while not self.done and len(self.result_buffer) == 0:
            i1 = self.instream.get()
            if i1 is None or i1['t1'] > self.cur_t1 + self.window:
                # release pending trackings
                for _, v in self.trackings.items():
                    # v is a list of (t1, x1, y1, x2, y2)
                    new_trajectory = []
                    for t1, x1, y1, x2, y2 in v:
                        new_trajectory.append(
                            Interval(Bounds3D(t1, t1+1, x1, x2, y1, y2))
                        )

                    new_bounds = functools.reduce(Bounds3D.span, [i.bounds for i in new_trajectory])
                    new_payload = {self.trajectory_key: new_trajectory}
                    self.result_buffer.append(Interval(new_bounds, new_payload))

                self.result_buffer.sort(key=lambda i: i['t1'])
                self.trackings.clear()

                if i1 is None:
                    self.done = True
                    break
                else:
                    # reset tracker and cur_t1
                    self.tracker = SORTTrack(self.max_age, self.min_hits, self.iou_threshold)
                    self.cur_t1 = i1['t1']

            dets = self.tracker.update(self.get_boxes_fn(i1))
            assert dets.shape[1] == 5, str(dets)
            for x1, y1, x2, y2, oid in dets:
                self.trackings[oid].append([i1['t1'], x1, y1, x2, y2])            
        

        if len(self.result_buffer) > 0:
            self.publish(self.result_buffer.pop(0))
            return True
        else:
            return False


from stsearch.third_party.opticalflow_mot.optical_flow.getFeatures import getFeatures
from stsearch.third_party.opticalflow_mot.optical_flow.estimateAllTranslation import estimateAllTranslation
from stsearch.third_party.opticalflow_mot.optical_flow.applyGeometricTransformation import applyGeometricTransformation

class TrackOpticalFlowFromBoxes(Graph):

    # https://github.com/jguoaj/multi-object-tracking
    
    def __init__(
        self, 
        get_boxes_fn: typing.Callable[[Interval], np.ndarray], 
        decoder: AbstractVideoDecoder, 
        window, 
        step=1, 
        trajectory_key='trajectory',
        name = None
        ):

        super().__init__()

        assert callable(get_boxes_fn)
        self.get_boxes_fn = get_boxes_fn
        self.decoder = decoder
        self.window = window
        self.step = step
        self.trajectory_key = trajectory_key
        self.name = name or f"{self.__class__.__name__}"

    def call(self, instream):
        decoder = self.decoder
        window = self.window
        step = self.step

        def flatten_fn(i1: Interval) -> typing.List[Interval]:            
            # buffer all frames in window at once
            start_fid = min(i1['t1'], decoder.frame_count - 1)  # inclusive
            end_fid = min(i1['t1'] + window, decoder.frame_count)  # exclusive
            frames_to_track = decoder.get_frame_interval(start_fid, end_fid, step)
            H, W = frames_to_track[0].shape[:2]

            initial_boxes_and_score = self.get_boxes_fn(i1)
            keep_track = tuple([ [ (i1['t1'], xmin, xmax, ymin, ymax),] for xmin, ymin, xmax, ymax, _ in initial_boxes_and_score ])

            # following code addapted from https://github.com/jguoaj/multi-object-tracking/blob/master/tracking.py
            # seems this code doesn't report lost track
            n_object = initial_boxes_and_score.shape[0]
            bboxs = np.empty((n_object,4,2), dtype=np.float)
            i = 0
            for row in initial_boxes_and_score:
                xmin, ymin, xmax, ymax, _ = row
                xmin, ymin, xmax, ymax = xmin*W, ymin*H, xmax*W, ymax*H
                xmin, ymin, boxw, boxh = int(xmin), int(ymin), int(xmax-xmin), int(ymax-ymin)
                bboxs[i,:,:] = np.array([[xmin,ymin],[xmin+boxw,ymin],[xmin,ymin+boxh],[xmin+boxw,ymin+boxh]]).astype(float)
                i = i+1

            startXs,startYs = getFeatures(cv2.cvtColor(frames_to_track[0],cv2.COLOR_RGB2GRAY),bboxs,use_shi=False)
            oldframe = frames_to_track[0]
            oldbboxs = bboxs

            for ts, frame in zip(range(start_fid + step, end_fid, step), frames_to_track[1:]):
                newXs, newYs = estimateAllTranslation(startXs, startYs, oldframe, frame)
                Xs, Ys, newbboxs = applyGeometricTransformation(startXs, startYs, newXs, newYs, oldbboxs)
                # update coordinates
                (startXs, startYs) = (Xs, Ys)

                oldframe = frame
                oldbboxs = newbboxs

                # update feature points as required
                n_features_left = np.sum(Xs!=-1)
                print('# of Features: %d'%n_features_left)
                if n_features_left < 15:
                    print('Generate New Features')
                    try:
                        startXs,startYs = getFeatures(cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY),newbboxs)
                    except:
                        print("frame:", frame.shape, frame)
                        print("newbboxs", newbboxs) # newbboxs can have NAN
                        raise

                # draw bounding box and visualize feature point for each object
                for j in range(n_object):
                    (xmin, ymin, boxw, boxh) = cv2.boundingRect(newbboxs[j,:,:].astype(int))
                    xmin, ymin, xmax, ymax = xmin, ymin, xmin+boxw, ymin+boxh
                    keep_track[j].append( (ts, xmin/W, xmax/W, ymin/H, ymax/H) )

            # Done. Conver keep_track into output
            rv = []
            for track in keep_track:
                new_trajectory = [
                    Interval(
                        Bounds3D(ts, ts+1, xmin, xmax, ymin, ymax)
                    )
                    for ts, xmin, xmax, ymin, ymax in track
                ]
                new_bounds = functools.reduce(Bounds3D.span, [i.bounds for i in new_trajectory])
                new_payload = {self.trajectory_key: new_trajectory}
                rv.append(Interval(new_bounds, new_payload))

            return rv # end of flatten_fn
        
        return Flatten(flatten_fn, self.name)(instream)
